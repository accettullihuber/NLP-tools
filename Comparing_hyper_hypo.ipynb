{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bdb372",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9301815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "#import the custom functions\n",
    "import MFunctions as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f820c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load verb_symilarity which is the same for all\n",
    "simdict = mf.verb_similarity(\"SimVerb-3500.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9e131",
   "metadata": {},
   "source": [
    "## Define the vector dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b4d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make observables object\n",
    "set5 = mf.observables([\"Linear.txt\",\"Quadratic.txt\",\"Cubic1.txt\",\"Quartic1.txt\",\"Additional1.txt\"])\n",
    "# Load matrices and make vector dictionaries\n",
    "objsubset5 = mf.vector_dictionary(\"matrices_1160_arg_obj_context_subj.txt\",set5)\n",
    "subobjset5 = mf.vector_dictionary(\"matrices_1160_arg_subj_context_obj.txt\",set5,[0])\n",
    "obj08sub02set5 = mf.vector_dictionary([[\"matrices_1160_arg_obj_context_subj.txt\",\"matrices_1160_arg_subj_context_obj.txt\"],[0.8,0.2]],set5,[1])\n",
    "obj09sub01set5 = mf.vector_dictionary([[\"matrices_1160_arg_obj_context_subj.txt\",\"matrices_1160_arg_subj_context_obj.txt\"],[0.9,0.1]],set5,[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadcb9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e71b6b",
   "metadata": {},
   "source": [
    "## Length of hypernyms vs hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c008a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the natural language processing libraries\n",
    "#import nltk\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "308ca6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract all the hyponyms of a given string\n",
    "def get_hyponyms(synset):\n",
    "    hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms |= set(get_hyponyms(hyponym))\n",
    "    return hyponyms | set(synset.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48706ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test whether the second word is a hyponym of the first\n",
    "def is_hyponym(hyper,hypo):\n",
    "    \n",
    "    #Extract all possible meanings of the given hyper string\n",
    "    allsyn = wn.synsets(hyper)\n",
    "    \n",
    "    # Initialise allhyponyms var to empty set\n",
    "    allhypo = set()\n",
    "    \n",
    "    #Loop over all the possible meanings of hyper, thus allsyn, and search for all the associated hyponyms\n",
    "    for syn in allsyn:\n",
    "        allhypo |= get_hyponyms(syn)\n",
    "    \n",
    "    #Check if the given hypo has any overlap with the set of hyponyms found\n",
    "    return allhypo.intersection(set(wn.synsets(hypo))) != set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489aec64",
   "metadata": {},
   "source": [
    "## Testing the lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14f63849",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairlist = [list(a) for a in np.array(simdict['HYPER/HYPONYMS']).T[:2].T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6958377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3733509234828496"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the lengths, how often is the hyper smaller than the hypo? Deviation vectors\n",
    "compare = []\n",
    "for a in pairlist[:243]+pairlist[250:515]+pairlist[550:800]:\n",
    "    local = [mf.M_vec_mult_dev(objsubset5[a[0]].val,objsubset5[a[0]].val,objsubset5.mean,objsubset5.std),mf.M_vec_mult_dev(objsubset5[a[1]].val,objsubset5[a[1]].val,objsubset5.mean,objsubset5.std)]\n",
    "    \n",
    "    if is_hyponym(a[0],a[1]):\n",
    "        compare.append(local[0]<local[1])\n",
    "    else :\n",
    "        compare.append(local[0]>local[1])\n",
    "print(len(compare))\n",
    "compare.count(False)/len(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6eccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
